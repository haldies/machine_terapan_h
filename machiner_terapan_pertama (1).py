# -*- coding: utf-8 -*-
"""machiner_terapan_pertama.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1W6-37o0aoDkoz81NAL6ob5T16h-3OIRe

# Predictive Analytics

## Import Semua Packages/Library yang Digunakan
"""

!pip install kaggle

"""Pada tahap ini, kita mengimpor semua library penting untuk analisis data, pembuatan model, tuning hyperparameter, dan visualisasi."""

import pandas as pd
import os
import numpy as np
import shutil

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.model_selection import GridSearchCV

from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier

from imblearn.over_sampling import SMOTENC
from imblearn.under_sampling import RandomUnderSampler

import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import files

import warnings
warnings.filterwarnings('ignore')

"""## Data Preparation

Tahapan ini bertujuan untuk memastikan data sudah tersedia sebelum masuk ke proses pemodelan. Jika menggunakan dataset publik, kita bisa mendownload atau menghubungkan ke sumber data seperti file CSV.

### Data Loading

Melakukan persiapan mengunduh dataset dari Kaggle, menyimpan file API key agar dapat mengakses Kaggle, dan mengekstrak data dari file ZIP yang diunduh.
"""

files.upload()

os.makedirs('/root/.kaggle', exist_ok=True)
os.rename('kaggle.json', '/root/.kaggle/kaggle.json')

!kaggle datasets download -d taweilo/loan-approval-classification-data

!unzip /content/loan-approval-classification-data.zip -d /content/data

"""###  Membaca dan Menampilkan Data dari File CSV"""

df = pd.read_csv('/content/data/loan_data.csv')
df

"""### Data Preprocessing

Sebelum membangun model, kita perlu mempersiapkan data:
- Mengecek dan menangani missing values.
- Memisahkan fitur dan target.
- Melakukan standardisasi fitur untuk memperbaiki performa model.

##### Melihat Informasi Umum Dataset
"""

df.info()

"""Dataset memiliki 45.000 baris dan 14 kolom.

Tidak ada missing value (semua kolom memiliki jumlah non-null yang sama dengan jumlah baris).

Tipe data:

- float64 untuk kolom numerik desimal seperti umur, penghasilan, jumlah pinjaman, dan suku bunga pinjaman.

- int64 untuk kolom numerik bilangan bulat seperti pengalaman kerja, skor kredit, dan status pinjaman.

- object untuk kolom kategorikal seperti jenis kelamin, pendidikan, dan kepemilikan rumah.

##### Statistik Deskriptif Dataset
"""

df.describe()

"""Terlihat adanya outlier pada person_age, person_emp_exp, dan person_income, sehingga perlu dilakukan pembersihan data (data cleaning)

- Usia (person_age): Nilai maksimal usia adalah 144, yang tidak realistis. Ini menunjukkan adanya outlier yang perlu diperiksa lebih lanjut.

- Pendapatan (person_income): Nilai maksimal yang sangat tinggi (7.2 juta), yang mungkin merupakan outlier. Biasanya, pendapatan ekstrem ini perlu dikoreksi.

- Pengalaman Kerja (person_emp_exp): Pengalaman kerja maksimal yang sangat tinggi (125 tahun) jelas merupakan outlier yang tidak wajar.

#### Mengecek Missing Values
"""

df.isnull().sum()

"""tidak ada yang missing values dataset nya

#### Membersihkan Data outliner
"""

df = df[df['person_age'] <= 100]
df = df[df['person_emp_exp'] <= 60]
df = df[df['person_income'] <= 500000]

df.describe()

"""disini menghapus data yang tidak masuk akal

- Hanya mempertahankan data dengan person_age (umur) â‰¤ 100 tahun.

- Hanya mempertahankan data dengan person_emp_exp (pengalaman kerja) â‰¤ 60 tahun.

- Hanya mempertahankan data dengan person_income (penghasilan) â‰¤ 500.000.

#### Visualisasi Distribusi Data: `person_age`, `person_emp_exp`, `loan_amnt`, `loan_int_rate`, `loan_percent_income`, `cb_person_cred_hist_length`dan `credit_score`
"""

sns.set(style="whitegrid")
plt.figure(figsize=(20, 16))
plt.subplot(3, 3, 1)
sns.histplot(df['person_age'], bins=30, kde=True, color='skyblue')
plt.title("Distribusi Umur")

plt.subplot(3, 3, 3)
sns.histplot(df['person_emp_exp'], bins=30, kde=True, color='orange')
plt.title("Distribusi Pengalaman Kerja")

plt.subplot(3, 3, 4)
sns.histplot(df['loan_amnt'], bins=30, kde=True, color='red')
plt.title("Distribusi Jumlah Pinjaman")

plt.subplot(3, 3, 5)
sns.histplot(df['loan_int_rate'], bins=30, kde=True, color='purple')
plt.title("Distribusi Bunga Pinjaman")

plt.subplot(3, 3, 6)
sns.histplot(df['loan_percent_income'], bins=30, kde=True, color='teal')
plt.title("Distribusi Pinjaman vs Pendapatan")

plt.subplot(3, 3, 7)
sns.histplot(df['cb_person_cred_hist_length'], bins=30, kde=True, color='brown')
plt.title("Distribusi Panjang Riwayat Kredit")

plt.subplot(3, 3, 8)
sns.histplot(df['credit_score'], bins=30, kde=True, color='gray')
plt.title("Distribusi Skor Kredit")

plt.subplot(3, 3, 9)
sns.countplot(x='loan_status', data=df, palette='pastel')
plt.title("Distribusi Status Pinjaman")
plt.xticks([0, 1], ['Tidak Gagal Bayar', 'Gagal Bayar'])

plt.tight_layout()
plt.show()

""".
1. **Distribusi Umur Pemohon (`person_age`)**
**Insight**:  
ðŸ”Ž Sebagian besar peminjam masih muda, di rentang usia produktif (20â€“30 tahun). Tapi perlu pembersihan data untuk outlier umur >100 tahun.

---

2. **Distribusi Pengalaman Kerja (`person_emp_exp`)**
**Insight**:  
ðŸ”Ž Banyak peminjam adalah pekerja awal karir (1â€“8 tahun pengalaman). Perlu menghapus pengalaman kerja tidak logis (di atas 60 tahun).

---

3. **Distribusi Jumlah Pinjaman (`loan_amnt`)**
**Insight**:  
ðŸ”Ž Sebagian besar pinjaman berada di kisaran kecil hingga menengah, cocok untuk pinjaman pribadi atau kebutuhan konsumtif.

---
4. **Distribusi Suku Bunga Pinjaman (`loan_int_rate`)**
**Insight**:  
ðŸ”Ž Rentang bunga cukup wajar untuk kredit konsumer. Mayoritas bunga berada antara **8%â€“13%**, artinya tidak terlalu mahal.

---

5. **Distribusi Rasio Pinjaman terhadap Pendapatan (`loan_percent_income`)**
**Insight**:  
ðŸ”Ž Kebanyakan peminjam hanya menggunakan sebagian kecil pendapatannya untuk membayar pinjaman, yang berarti beban cicilan masih **cukup aman**.

---

6. **Distribusi Panjang Riwayat Kredit (`cb_person_cred_hist_length`)**
**Insight**:  
ðŸ”Ž Banyak peminjam baru memiliki riwayat kredit pendek (sekitar 3â€“8 tahun), menandakan banyaknya peminjam generasi muda atau baru mulai membangun kredit.

---

7. **Distribusi Skor Kredit (`credit_score`)**
**Insight**:  
ðŸ”Ž Skor rata-rata ada di **kategori wajar** (600â€“700), tapi ada juga yang rendah (di bawah 600) yang perlu perhatian lebih karena berisiko default.

---

#### Melihat visualisasi Distribusi Data Kategorikal
"""

plt.figure(figsize=(12, 18))

plt.subplot(6, 2, 1)
sns.countplot(x='person_gender', data=df, palette='Set1')
plt.title('Distribusi Gender')

plt.subplot(6, 2, 2)
sns.countplot(x='person_education', data=df, palette='Set1')
plt.title('Distribusi Pendidikan')

plt.subplot(6, 2, 3)
sns.countplot(x='person_home_ownership', data=df, palette='Set1')
plt.title('Distribusi Kepemilikan Rumah')

plt.subplot(6, 2, 4)
sns.countplot(x='previous_loan_defaults_on_file', data=df, palette='Set1')
plt.title('Distribusi Default Pinjaman Sebelumnya')

plt.subplot(6, 2, 5)
sns.countplot(x='loan_status', data=df, palette='Set1')
plt.title('Distribusi Status Pinjaman')

plt.tight_layout()

plt.show()

"""1. **Distribusi Gender (`person_gender`)**
**Insight**:  
ðŸ”Ž Jumlah peminjam laki-laki sedikit lebih banyak dibanding perempuan. Ini menunjukkan bahwa partisipasi dalam pengajuan pinjaman didominasi laki-laki, tapi perbedaannya tidak terlalu jauh.

---

2. **Distribusi Pendidikan (`person_education`)**
**Insight**:  
ðŸ”Ž Mayoritas peminjam memiliki pendidikan minimal SMA hingga S1. Jumlah yang berpendidikan Master dan Doctorate cukup kecil, yang wajar karena semakin tinggi pendidikan, biasanya profil peminjam lebih sedikit.

---

3. **Distribusi Kepemilikan Rumah (`person_home_ownership`)**
**Insight**:  
ðŸ”Ž Sebagian besar peminjam tinggal di rumah sewa atau sedang dalam cicilan KPR. Ini bisa berarti banyak peminjam berada dalam tahap membangun aset dan belum memiliki rumah pribadi sepenuhnya.

---

4. **Distribusi Default Pinjaman Sebelumnya (`previous_loan_defaults_on_file`)**
**Insight**:  
ðŸ”Ž Jumlah peminjam yang pernah mengalami gagal bayar hampir sama dengan yang tidak. Ini mengindikasikan dataset mengandung risiko yang cukup besar dan perlu perhatian dalam analisis risiko pinjaman.

---

5. **Distribusi Status Pinjaman (`loan_status`)**
**Insight**:  
ðŸ”Ž Distribusi data pada kolom loan_status menunjukkan bahwa data pinjaman sekitar (77,8%) tidak disetujui (loan_status = 0) dan data pinjaman sekitar (22,2%) yang disetujui (loan_status = 1). Hal ini menunjukkan ketidakseimbangan data (data imbalance), yang penting diperhatikan saat melakukan analisis atau pelatihan model prediksi, karena model bisa cenderung memprediksi mayoritas kelas.

---

#### Melihat Heatmap Korelasi dataset
"""

plt.figure(figsize=(12, 8))
sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Heatmap Korelasi Antar Variabel Numerik")
plt.show()

"""hasil matriks korelasi di atas, variabel yang memiliki hubungan paling kuat dengan loan_status (status kelolosan pinjaman) adalah loan_percent_income (0.38) dan loan_int_rate (0.33), yang artinya semakin tinggi persentase pinjaman terhadap pendapatan atau suku bunga, semakin besar kemungkinan pengajuan pinjaman lolos. Sementara variabel seperti person_age, person_income, dan credit_score memiliki korelasi negatif lemah terhadap loan_status, menunjukkan pengaruh yang kecil. Secara umum, tidak ada korelasi yang sangat kuat (mendekati 1 atau -1), namun dua variabel tadi bisa menjadi kandidat penting dalam analisis prediksi status pinjaman.

#### Label Encoding Data  
Fitur kategorikal perlu dikonversi terlebih dahulu menjadi nilai numerik agar dapat digunakan dalam algoritma machine learning. Proses ini dilakukan menggunakan **Label Encoding**, yaitu teknik yang mengubah setiap kategori unik menjadi representasi angka. Contohnya, fitur `"gender"` dengan nilai `"male"` dan `"female"` akan dikonversi menjadi `0` dan `1`.

Langkah ini **sangat penting dilakukan sebelum proses Data Balancing menggunakan SMOTENC**, karena:

- **SMOTENC tidak dapat memproses data dalam bentuk string atau objek kategori.**
- SMOTENC membutuhkan seluruh data, baik numerik maupun kategorikal, dalam format numerik agar dapat melakukan proses oversampling.
- Setelah Label Encoding dilakukan, fitur kategorikal yang telah dikonversi menjadi angka dapat ditandai dalam parameter `categorical_features` pada SMOTENC, sehingga metode ini tetap memperlakukan fitur tersebut sebagai kategorikal, bukan numerik biasa.

Dengan demikian, **Label Encoding dilakukan sebelum Data Balancing** agar data siap diproses oleh SMOTENC secara optimal dan menjaga struktur asli dari fitur kategorikal dalam proses pembangkitan data sintetis.
"""

df_resampled = df.copy()

label_encoder = LabelEncoder()

df_resampled['person_gender'] = label_encoder.fit_transform(df_resampled['person_gender'])
df_resampled['previous_loan_defaults_on_file'] = label_encoder.fit_transform(df_resampled['previous_loan_defaults_on_file'])

df_resampled['person_home_ownership'] = label_encoder.fit_transform(df_resampled['person_home_ownership'])

df_resampled = pd.get_dummies(df_resampled, columns=['person_education', 'loan_intent'], drop_first=True)

df_resampled

"""#### Penyeimbangan Data (Data Balancing)
Distribusi variabel target `loan_status` dalam dataset sangat tidak seimbang, dengan sekitar 77,8% data berada pada kelas ditolak (0) dan hanya 22,2% disetujui (1), sehingga model cenderung bias ke kelas mayoritas. Untuk mengatasi hal ini, digunakan teknik SMOTENC (Synthetic Minority Oversampling Technique for Nominal and Continuous) karena dataset mengandung kombinasi fitur kategorikal dan numerik. Pertama, fitur input (`X`) dan target (`y`) dipisahkan, lalu fitur kategorikal ditentukan berdasarkan indeks kolom. Dengan SMOTENC, data kelas minoritas (1) di-*oversample* hingga mencapai **15.000** data. Selanjutnya, digunakan RandomUnderSampler untuk mengurangi data dari kelas mayoritas (0) menjadi 15.000 juga, sehingga kedua kelas seimbang. Data hasil balancing ini kemudian digabungkan kembali ke dalam DataFrame baru `df_resampled` yang memiliki distribusi kelas 0 dan 1 masing-masing sebanyak 15.000, dan siap digunakan untuk pelatihan model secara lebih adil.
"""

X = df_resampled.drop('loan_status', axis=1)
y = df_resampled['loan_status']

categorical_features = [2, 5]

smote_nc = SMOTENC(categorical_features=categorical_features, sampling_strategy={1: 15000}, random_state=42)

X_oversampled, y_oversampled = smote_nc.fit_resample(X, y)

undersampler = RandomUnderSampler(sampling_strategy={0: 15000}, random_state=42)
X_resampled, y_resampled = undersampler.fit_resample(X_oversampled, y_oversampled)

df_resampled = pd.DataFrame(X_resampled, columns=X.columns)
df_resampled['loan_status'] = y_resampled

print(df_resampled['loan_status'].value_counts())

df_resampled

"""####  Split Dataset
tahap ini melakukan pemisahkan dataset df_resampled menjadi dua bagian: fitur input (X) dan target (y), di mana X berisi semua kolom kecuali loan_status dan y adalah kolom loan_status yang ingin diprediksi. Kemudian, menggunakan fungsi train_test_split(), data dibagi menjadi dua set, yaitu 80% data untuk pelatihan (X_train, y_train) dan 20% sisanya untuk pengujian (X_test, y_test), dengan pembagian yang konsisten setiap kali kode dijalankan berkat pengaturan random_state=42.
"""

X = df_resampled.drop(columns=['loan_status'])
y = df_resampled['loan_status']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""## Modelling
untuk tahap ini, digunakan tiga algoritma machine learning untuk menyelesaikan permasalahan klasifikasi status pinjaman, yaitu **Logistic Regression**, **Random Forest Classifier**, dan **XGBoost Classifier**. Pemilihan ketiga algoritma ini didasarkan pada pertimbangan variasi kompleksitas, kemampuan generalisasi, serta efisiensi komputasi.

#### Logistic Regression
ditahap ini membuat model Logistic Regression dengan parameter max_iter=1000 untuk memastikan model memiliki cukup iterasi untuk konvergen, dan random_state=42 agar hasilnya dapat direproduksi. Kemudian, model tersebut dilatih menggunakan data latih (X_train, y_train) dengan memanggil metode .fit(). Setelah proses pelatihan selesai, model digunakan untuk membuat prediksi pada data uji (X_test) dengan metode .predict(), dan hasil prediksinya disimpan dalam variabel y_pred_logreg
"""

logreg_model = LogisticRegression(max_iter=1000, random_state=42)
logreg_model.fit(X_train, y_train)
y_pred_logreg = logreg_model.predict(X_test)

print("=== Logistic Regression (Default) ===")
print(classification_report(y_test, y_pred_logreg))

"""insight :
Hasil ini menunjukkan bahwa model **Logistic Regression** memiliki **akurasi 88%** secara keseluruhan, dengan performa yang cukup baik dalam memprediksi kedua kelas. Untuk kelas 0 (ditolak), **precision** 93% dan **recall** 83% menunjukkan bahwa model lebih sering memprediksi benar pinjaman yang ditolak, meskipun ada beberapa data yang terlewat. Sementara itu, untuk kelas 1 (disetujui), **precision** 84% dan **recall** 93% menunjukkan bahwa model lebih akurat dalam memprediksi pinjaman yang disetujui. F1-score yang seimbang di kedua kelas (0.88) mencerminkan keseimbangan yang baik antara precision dan recall. Secara keseluruhan, model ini menunjukkan performa yang solid dengan distribusi prediksi yang wajar antara kedua kelas.

####  Random Forest
"""

rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)
print("=== Random Forest (Default) ===")
print(classification_report(y_test, y_pred_rf))

"""Model **Random Forest** memberikan **akurasi 91%**, lebih baik dibandingkan Logistic Regression. Model ini menunjukkan **precision, recall, dan F1-score** yang seimbang dan tinggi (sekitar 0.91) untuk kedua kelas (ditolak dan disetujui), dengan performa lebih baik dalam memprediksi kelas 1 (disetujui). Secara keseluruhan, Random Forest lebih efektif dalam memprediksi kedua kelas secara akurat dan konsisten, menunjukkan kemampuan yang lebih baik dibandingkan model Logistic Regression.

#### XGBoost
"""

xgb_model = XGBClassifier(
    use_label_encoder=False,
    eval_metric='logloss',
    random_state=42
)
xgb_model.fit(X_train, y_train)
y_pred_xgb = xgb_model.predict(X_test)

print("=== XGBoost (Default) ===")
print(classification_report(y_test, y_pred_xgb))

"""Hasil dari model **XGBoost (Default)** menunjukkan **akurasi 92%** secara keseluruhan. Untuk kelas 0 (ditolak), model memiliki **precision** 93% dan **recall** 91%, sementara untuk kelas 1 (disetujui), **precision** 91% dan **recall** 93%. F1-score yang konsisten tinggi (0.92) di kedua kelas menunjukkan keseimbangan yang baik antara precision dan recall. Secara keseluruhan, model ini menunjukkan performa yang solid dengan distribusi prediksi yang seimbang antara kedua kelas.

## Improvement model dengan hyperparameter tuning
Untuk meningkatkan performa, dilakukan proses **GridSearchCV** terhadap kombinasi parameter yang relevan. Berikut alasan pemilihan parameter untuk masing-masing model:

#### Logistic regression tuning

Melakukan hyperparameter tuning pada model Logistic Regression menggunakan GridSearchCV Pencarian dilakukan dengan kombinasi parameter C, penalty, solver, dan max_iter, menggunakan 5-fold cross-validation dan penilaian berdasarkan F1 Score Hasilnya akan menampilkan parameter terbaik dan skor F1 tertinggi yang diperoleh.
"""

param_grid_logreg = {
    'C': [0.01, 0.1, 1, 10],
    'penalty': ['l2'],
    'solver': ['lbfgs', 'saga'],
    'max_iter': [500, 1000]
}

grid_logreg = GridSearchCV(
    LogisticRegression(random_state=42),
    param_grid_logreg,
    cv=5,
    scoring='f1',
    n_jobs=-1
)
grid_logreg.fit(X_train, y_train)

print("Best parameters (Logistic Regression):", grid_logreg.best_params_)
print("Best score:", grid_logreg.best_score_)

"""Insight: Model Logistic Regression mendapatkan performa terbaik saat menggunakan C=10, penalty='l2', solver='lbfgs', dan max_iter=1000. Nilai C yang besar (10) menunjukkan model lebih kompleks dan sedikit toleransi terhadap kesalahan. Solver 'lbfgs' cocok untuk dataset skala kecil hingga sedang,
dan iterasi maksimal 1000 membantu model mencapai konvergensi. Skor F1 sebesar 0.88 menunjukkan bahwa model memiliki keseimbangan yang baik antara precision dan recall, sehingga cocok untuk masalah klasifikasi dengan kebutuhan keseimbangan antara kedua metrik tersebut.

#### Random Forest tuning
Melakukan hyperparameter tuning pada model Random Forest menggunakan GridSearchCV. Pencarian dilakukan dengan mencoba kombinasi parameter n_estimators, max_depth ,min_samples_split, min_samples_leaf, dan max_features. Evaluasi dilakukan menggunakan 5-fold cross-validation dan F1 Score sebagai metrik penilaian. Hasilnya akan menampilkan kombinasi parameter terbaik dan skor F1 tertinggi yang diperoleh.
"""

param_grid_rf = {
    'n_estimators': [100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 4],
    'max_features': ['sqrt']
}

grid_rf = GridSearchCV(
    RandomForestClassifier(random_state=42),
    param_grid_rf,
    cv=5,
    scoring='f1',
    n_jobs=-1
)
grid_rf.fit(X_train, y_train)

print("Best parameters (Random Forest):", grid_rf.best_params_)
print("Best score:", grid_rf.best_score_)

"""Insight: Model Random Forest mencapai performa terbaik saat menggunakan n_estimators=200, max_depth=None,max_features='sqrt', min_samples_split=2, dan min_samples_leaf=1. max_depth=None berarti pohon dibiarkan tumbuh bebas sampai semua daun sempurna, membantu model menangkap kompleksitas data dengan lebih baik. Penggunaan n_estimators=200 meningkatkan stabilitas prediksi karena lebih banyak pohon yang digabung. min_samples_split=2 dan min_samples_leaf=1 membuat model lebih fleksibel terhadap pola data yang kecil. Pemilihan max_features='sqrt' membantu mengurangi overfitting dengan memilih subset fitur secara acak. Skor F1 sebesar 0.91 menunjukkan bahwa model ini sangat baik dalam menyeimbangkan precision dan recall, sehingga sangat cocok untuk masalah klasifikasi yang sensitif terhadap kesalahan klasifikasi.

#### XGboost tuning
Melakukan hyperparameter tuning pada model XGBoost menggunakan GridSearchCV. Pencarian dilakukan dengan kombinasi parameter n_estimators, max_depth, learning_rate,subsample, dan colsample_bytree. Proses tuning menggunakan 3-fold cross-validation dan mengevaluasi model berdasarkan F1 Score. Hasilnya akan menampilkan kombinasi parameter terbaik dan skor F1 tertinggi yang diperoleh.
"""

param_grid_xgb = {
    'n_estimators': [100, 300],
    'max_depth': [3, 6, 10],
    'learning_rate': [0.01, 0.1, 0.2],
    'subsample': [0.8, 1],
    'colsample_bytree': [0.8, 1]
}

grid_xgb = GridSearchCV(
    XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),
    param_grid_xgb,
    cv=3,
    scoring='f1',
    n_jobs=-1
)
grid_xgb.fit(X_train, y_train)

print("Best parameters (XGBoost):", grid_xgb.best_params_)
print("Best score:", grid_xgb.best_score_)

"""Insight:
Model XGBoost mendapatkan performa terbaik dengan n_estimators=300, max_depth=10, learning_rate=0.1,subsample=1, dan colsample_bytree=0.8. max_depth=10 memungkinkan model menangkap pola kompleks dalam data, sementara learning_rate=0.1 menjaga agar pembelajaran tetap stabil dan tidak terlalu agresif. Penggunaan n_estimators=300 memberikan cukup banyak pohon untuk meningkatkan akurasi model. Setting subsample=1 berarti seluruh data digunakan di setiap iterasi, sedangkan colsample_bytree=0.8 membantu mencegah overfitting dengan hanya menggunakan 80% fitur di setiap pohon.
Skor F1 sebesar 0.92 menunjukkan bahwa XGBoost memiliki performa paling tinggi di antara model lain, dengan keseimbangan yang sangat baik antara precision dan recall untuk tugas klasifikasi ini.

## Evaluasi dan Visualisasi
Menampilkan laporan evaluasi model menggunakan classification_report

#### Hasil Laporan Evaluasi Logistic Regression
"""

best_logreg = grid_logreg.best_estimator_
y_pred_logreg = best_logreg.predict(X_test)

print("=== Logistic Regression (Tuned) ===")
print(classification_report(y_test, y_pred_logreg))

"""Insight:Model Logistic Regression yang sudah dituning menunjukkan performa yang cukup baik pada data uji. Untuk kelas 0, precision adalah 0.93, yang berarti dari semua prediksi kelas 0, 93% benar. Recall untuk kelas 0 adalah 0.83, yang artinya 83% dari semua data kelas 0 berhasil diprediksi dengan benar. F1-score untuk kelas 0 adalah 0.87, menunjukkan keseimbangan antara precision dan recall. Untuk kelas 1, precision adalah 0.84, recall 0.93, dan f1-score 0.88, yang menunjukkan model lebih baik dalam mendeteksi kelas 1 (tinggi recall), meskipun precision-nya sedikit lebih rendah dibandingkan kelas 0. Akurasi keseluruhan model adalah 0.88, yang berarti model berhasil memprediksi dengan benar 88% dari data uji.Skor rata-rata (macro avg dan weighted avg) untuk precision, recall, dan f1-score semuanya berada di 0.88, menunjukkan keseimbangan performa model secara keseluruhan di kedua kelas.

#### Hasil Laporan Evaluasi Random Forest
"""

best_rf = grid_rf.best_estimator_
y_pred_rf = best_rf.predict(X_test)

print("=== Random Forest (Tuned) ===")
print(classification_report(y_test, y_pred_rf))

"""Insight:
Model Random Forest yang sudah dituning menunjukkan performa yang sangat baik pada data uji. Untuk kelas 0, precision adalah 0.94, yang berarti 94% dari semua prediksi kelas 0 benar. Recall untuk kelas 0 adalah 0.89, yang menunjukkan 89% dari semua data kelas 0 berhasil diprediksi dengan benar. F1-score untuk kelas 0 adalah 0.91, menunjukkan keseimbangan yang baik antara precision dan recall. Untuk kelas 1, precision adalah 0.89, recall 0.94, dan f1-score 0.92, yang berarti model lebih baik dalam mendeteksi kelas 1 (tinggi recall), sementara precision-nya sedikit lebih rendah dibandingkan kelas 0. Akurasi keseluruhan model adalah 0.91, yang menunjukkan bahwa model ini benar memprediksi 91% dari data uji. Skor rata-rata (macro avg dan weighted avg) untuk precision, recall, dan f1-score semuanya berada di 0.91-0.92,menandakan model memiliki performa yang seimbang dan baik di kedua kelas.

#### Hasil Laporan Evaluasi Xgboost
"""

best_xgb = grid_xgb.best_estimator_
y_pred_xgb = best_xgb.predict(X_test)

print("=== XGBoost (Tuned) ===")
print(classification_report(y_test, y_pred_xgb))

"""Insight:
Model XGBoost yang sudah dituning menunjukkan performa luar biasa pada data uji. Untuk kelas 0, precision adalah 0.94, yang berarti 94% dari semua prediksi kelas 0 benar. Recall untuk kelas 0 adalah 0.91, yang menunjukkan 91% dari semua data kelas 0 berhasil diprediksi dengan benar. F1-score untuk kelas 0 adalah 0.93, menunjukkan keseimbangan yang sangat baik antara precision dan recall. Untuk kelas 1, precision adalah 0.91, recall 0.94, dan f1-score 0.93, yang menunjukkan bahwa model juga sangat baik dalam mendeteksi kelas 1, dengan sedikit trade-off antara precision dan recall. Akurasi keseluruhan model adalah 0.93, yang berarti model berhasil memprediksi 93% dari data uji dengan benar. Skor rata-rata (macro avg dan weighted avg) untuk precision, recall, dan f1-score semuanya berada di 0.93,
menunjukkan performa yang sangat seimbang dan sangat baik di kedua kelas.

"""